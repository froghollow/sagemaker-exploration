{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e19e0cd5",
   "metadata": {},
   "source": [
    "# PySpark & PyDeequ Shakeout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b1538ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: pydeequ in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.0.1)\n",
      "Requirement already satisfied: pandas>=0.23.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydeequ) (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.14.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydeequ) (1.22.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas>=0.23.0->pydeequ) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas>=0.23.0->pydeequ) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas>=0.23.0->pydeequ) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install pydeequ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bc7c564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip dependencies from local file, since Maven is blocked from within WC2(H) VPC\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "#S_rootdir = \"/home/ec2-user/SageMaker/RMyers/sagemaker-exploration\"\n",
    "S_rootdir = os.getcwd()\n",
    "\n",
    "with zipfile.ZipFile( f\"{S_rootdir}/common/ivy2cache.zip\" ) as z:\n",
    "    z.extractall( f\"{os.environ['HOME']}/.ivy2\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4302e6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Please set env variable SPARK_VERSION\n",
      "Warning: Ignoring non-Spark config property: fs.s3a.endpoint\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/ec2-user/.ivy2/cache\n",
      "The jars for the packages stored in: /home/ec2-user/.ivy2/jars\n",
      "com.amazon.deequ#deequ added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-f522a2b6-c0a7-49ec-9055-128c88400b8e;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.amazon.deequ#deequ;1.2.2-spark-3.0 in central\n",
      "\tfound org.scalanlp#breeze_2.12;0.13.2 in central\n",
      "\tfound org.scalanlp#breeze-macros_2.12;0.13.2 in central\n",
      "\tfound org.scala-lang#scala-reflect;2.12.1 in central\n",
      "\tfound com.github.fommil.netlib#core;1.1.2 in central\n",
      "\tfound net.sf.opencsv#opencsv;2.3 in central\n",
      "\tfound com.github.rwl#jtransforms;2.4.0 in central\n",
      "\tfound junit#junit;4.8.2 in central\n",
      "\tfound org.apache.commons#commons-math3;3.2 in central\n",
      "\tfound org.spire-math#spire_2.12;0.13.0 in central\n",
      "\tfound org.spire-math#spire-macros_2.12;0.13.0 in central\n",
      "\tfound org.typelevel#machinist_2.12;0.6.1 in central\n",
      "\tfound com.chuusai#shapeless_2.12;2.3.2 in central\n",
      "\tfound org.typelevel#macro-compat_2.12;1.1.1 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.5 in central\n",
      ":: resolution report :: resolve 722ms :: artifacts dl 34ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazon.deequ#deequ;1.2.2-spark-3.0 from central in [default]\n",
      "\tcom.chuusai#shapeless_2.12;2.3.2 from central in [default]\n",
      "\tcom.github.fommil.netlib#core;1.1.2 from central in [default]\n",
      "\tcom.github.rwl#jtransforms;2.4.0 from central in [default]\n",
      "\tjunit#junit;4.8.2 from central in [default]\n",
      "\tnet.sf.opencsv#opencsv;2.3 from central in [default]\n",
      "\torg.apache.commons#commons-math3;3.2 from central in [default]\n",
      "\torg.scala-lang#scala-reflect;2.12.1 from central in [default]\n",
      "\torg.scalanlp#breeze-macros_2.12;0.13.2 from central in [default]\n",
      "\torg.scalanlp#breeze_2.12;0.13.2 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.5 from central in [default]\n",
      "\torg.spire-math#spire-macros_2.12;0.13.0 from central in [default]\n",
      "\torg.spire-math#spire_2.12;0.13.0 from central in [default]\n",
      "\torg.typelevel#machinist_2.12;0.6.1 from central in [default]\n",
      "\torg.typelevel#macro-compat_2.12;1.1.1 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\torg.scala-lang#scala-reflect;2.12.0 by [org.scala-lang#scala-reflect;2.12.1] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   16  |   0   |   0   |   1   ||   15  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-f522a2b6-c0a7-49ec-9055-128c88400b8e\n",
      "\tconfs: [default]\n",
      "\t15 artifacts copied, 0 already retrieved (32953kB/104ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/19 17:00:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/19 17:00:07 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "23/04/19 17:00:07 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession, Row, DataFrame\n",
    "\n",
    "import sagemaker_pyspark\n",
    "import pydeequ\n",
    "\n",
    "classpath = \":\".join(sagemaker_pyspark.classpath_jars())\n",
    "\n",
    "from pyspark import SparkConf\n",
    "conf = (SparkConf()\n",
    "        .set('fs.s3a.endpoint', 's3-us-gov-west-1.amazonaws.com')\n",
    "       )\n",
    "\n",
    "spark = (SparkSession\n",
    "    .builder\n",
    "    .config(\"spark.driver.extraClassPath\", classpath)\n",
    "    .config(\"spark.jars.packages\", pydeequ.deequ_maven_coord)\n",
    "    .config(\"spark.jars.excludes\", pydeequ.f2j_maven_coord)\n",
    "    .config( conf=conf )\n",
    "    .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16b121b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/JupyterSystemEnv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "openjdk version \"11.0.1\" 2018-10-16 LTS\n",
      "OpenJDK Runtime Environment Zulu11.2+3 (build 11.0.1+13-LTS)\n",
      "OpenJDK 64-Bit Server VM Zulu11.2+3 (build 11.0.1+13-LTS, mixed mode)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "echo $JAVA_HOME\n",
    "$JAVA_HOME/bin/java -version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "661989fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Record Date: timestamp (nullable = true)\n",
      " |-- Creditor Agency Name: string (nullable = true)\n",
      " |-- Agency ID: integer (nullable = true)\n",
      " |-- Agency Site Type Code: string (nullable = true)\n",
      " |-- Agency Site ID: string (nullable = true)\n",
      " |-- Agency Site Name: string (nullable = true)\n",
      " |-- Source Agency Alpha: string (nullable = true)\n",
      " |-- Source Agency Numeric: string (nullable = true)\n",
      " |-- Source Agency Site ID: string (nullable = true)\n",
      " |-- Agency Name: string (nullable = true)\n",
      " |-- Payment Agency ID: string (nullable = true)\n",
      " |-- Agency Type Code: string (nullable = true)\n",
      " |-- Payment Source Description: string (nullable = true)\n",
      " |-- Payment Source Code: string (nullable = true)\n",
      " |-- Payment Category Description: string (nullable = true)\n",
      " |-- Payment Type Description: string (nullable = true)\n",
      " |-- Payment Type Code: string (nullable = true)\n",
      " |-- Payment Type ID: integer (nullable = true)\n",
      " |-- Debt Type Code: string (nullable = true)\n",
      " |-- Debt Type Description: string (nullable = true)\n",
      " |-- Taxable Indicator: string (nullable = true)\n",
      " |-- Total Gross Amount: double (nullable = true)\n",
      " |-- Total Net Amount: double (nullable = true)\n",
      " |-- Total Gross Count: integer (nullable = true)\n",
      " |-- Total Net Count: integer (nullable = true)\n",
      " |-- Fiscal Year: integer (nullable = true)\n",
      " |-- Fiscal Quarter Number: integer (nullable = true)\n",
      " |-- Calendar Year: integer (nullable = true)\n",
      " |-- Calendar Quarter Number: integer (nullable = true)\n",
      " |-- Calendar Month Number: integer (nullable = true)\n",
      " |-- Calendar Day Number: integer (nullable = true)\n",
      "\n",
      "23/04/19 17:00:24 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "+-------------------+--------------------+---------+---------------------+--------------+--------------------+-------------------+---------------------+---------------------+--------------------+-----------------+----------------+--------------------------+-------------------+----------------------------+------------------------+-----------------+---------------+--------------+---------------------+-----------------+------------------+----------------+-----------------+---------------+-----------+---------------------+-------------+-----------------------+---------------------+-------------------+\n",
      "|        Record Date|Creditor Agency Name|Agency ID|Agency Site Type Code|Agency Site ID|    Agency Site Name|Source Agency Alpha|Source Agency Numeric|Source Agency Site ID|         Agency Name|Payment Agency ID|Agency Type Code|Payment Source Description|Payment Source Code|Payment Category Description|Payment Type Description|Payment Type Code|Payment Type ID|Debt Type Code|Debt Type Description|Taxable Indicator|Total Gross Amount|Total Net Amount|Total Gross Count|Total Net Count|Fiscal Year|Fiscal Quarter Number|Calendar Year|Calendar Quarter Number|Calendar Month Number|Calendar Day Number|\n",
      "+-------------------+--------------------+---------+---------------------+--------------+--------------------+-------------------+---------------------+---------------------+--------------------+-----------------+----------------+--------------------------+-------------------+----------------------------+------------------------+-----------------+---------------+--------------+---------------------+-----------------+------------------+----------------+-----------------+---------------+-----------+---------------------+-------------+-----------------------+---------------------+-------------------+\n",
      "|2022-10-01 00:00:00|Bureau of the Fis...|       83|              Federal|          33MK|33-MK-BUREAU OF F...|                 33|                   51|                   MK|Internal Revenue ...|              132|         Federal|                Tax Refund|                TAX|                         TDO|          Tax Refund EFT|               IE|             12|            FN|      FEDERAL NON-TAX|                N|             986.0|           986.0|                1|              1|       2023|                    1|         2022|                      4|                   10|                  1|\n",
      "|2022-10-01 00:00:00|Bureau of the Fis...|       83|              Federal|          33M7|33-M7-FISCAL SERV...|                 33|                   1C|                   M7|Department of Hom...|               21|           State|            Vendor payment|                VEN|                         TDO|              Vendor EFT|               VE|             13|            FN|      FEDERAL NON-TAX|                N|             289.6|           289.6|                5|              5|       2023|                    1|         2022|                      4|                   10|                  1|\n",
      "|2022-10-01 00:00:00|Bureau of the Fis...|       83|              Federal|          33M7|33-M7-FISCAL SERV...|                 33|                   18|                   M7|Office of Personn...|               17|         Federal|      Office of Personn...|                OPM|                         TDO|                 OPM EFT|               OE|              8|            FN|      FEDERAL NON-TAX|                N|          91000.38|        90170.87|             1351|           1340|       2023|                    1|         2022|                      4|                   10|                  1|\n",
      "|2022-10-01 00:00:00|Bureau of the Fis...|       83|              Federal|          33M7|33-M7-FISCAL SERV...|                 33|                   18|                   M7|Office of Personn...|               17|         Federal|      Office of Personn...|                OPM|                         TDO|               OPM Check|               OC|              8|            FN|      FEDERAL NON-TAX|                N|             992.8|          882.83|               13|             11|       2023|                    1|         2022|                      4|                   10|                  1|\n",
      "|2022-10-01 00:00:00|Bureau of the Fis...|       83|              Federal|          33M7|33-M7-FISCAL SERV...|                 33|                   03|                   M7|Dept. of Health &...|                3|         Federal|            Vendor payment|                VEN|                         TDO|              Vendor EFT|               VE|             13|            FN|      FEDERAL NON-TAX|                N|           1352.94|         1352.94|               19|             19|       2023|                    1|         2022|                      4|                   10|                  1|\n",
      "+-------------------+--------------------+---------+---------------------+--------------+--------------------+-------------------+---------------------+---------------------+--------------------+-----------------+----------------+--------------------------+-------------------+----------------------------+------------------------+-----------------+---------------+--------------+---------------------+-----------------+------------------+----------------+-----------------+---------------+-----------+---------------------+-------------+-----------------------+---------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File output: data/TOP_FedClct_20221001_20221001.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Read a CSV file from local instance directory into a Spark dataframe\n",
    "file_input = 'data/TOP_FedClct_20221001_20221001.csv'\n",
    "\n",
    "df = spark.read \\\n",
    "    .format(\"com.databricks.spark.csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .option(\"delimiter\", \",\") \\\n",
    "    .load(file_input) \n",
    "\n",
    "df.printSchema()\n",
    "df.show(5)\n",
    "\n",
    "# Write a copy of the Spark dataframe to a Parquet output file\n",
    "file_output = file_input.replace('.csv', '.parquet')\n",
    "df.write.mode('overwrite').parquet(file_output)\n",
    "print(f'File output: {file_output}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0d46c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Record Date: timestamp (nullable = true)\n",
      " |-- Creditor Agency Name: string (nullable = true)\n",
      " |-- Agency ID: integer (nullable = true)\n",
      " |-- Agency Site Type Code: string (nullable = true)\n",
      " |-- Agency Site ID: string (nullable = true)\n",
      " |-- Agency Site Name: string (nullable = true)\n",
      " |-- Source Agency Alpha: string (nullable = true)\n",
      " |-- Source Agency Numeric: string (nullable = true)\n",
      " |-- Source Agency Site ID: string (nullable = true)\n",
      " |-- Agency Name: string (nullable = true)\n",
      " |-- Payment Agency ID: string (nullable = true)\n",
      " |-- Agency Type Code: string (nullable = true)\n",
      " |-- Payment Source Description: string (nullable = true)\n",
      " |-- Payment Source Code: string (nullable = true)\n",
      " |-- Payment Category Description: string (nullable = true)\n",
      " |-- Payment Type Description: string (nullable = true)\n",
      " |-- Payment Type Code: string (nullable = true)\n",
      " |-- Payment Type ID: integer (nullable = true)\n",
      " |-- Debt Type Code: string (nullable = true)\n",
      " |-- Debt Type Description: string (nullable = true)\n",
      " |-- Taxable Indicator: string (nullable = true)\n",
      " |-- Total Gross Amount: double (nullable = true)\n",
      " |-- Total Net Amount: double (nullable = true)\n",
      " |-- Total Gross Count: integer (nullable = true)\n",
      " |-- Total Net Count: integer (nullable = true)\n",
      " |-- Fiscal Year: integer (nullable = true)\n",
      " |-- Fiscal Quarter Number: integer (nullable = true)\n",
      " |-- Calendar Year: integer (nullable = true)\n",
      " |-- Calendar Quarter Number: integer (nullable = true)\n",
      " |-- Calendar Month Number: integer (nullable = true)\n",
      " |-- Calendar Day Number: integer (nullable = true)\n",
      "\n",
      "+-------------------+--------------------+---------+---------------------+--------------+--------------------+-------------------+---------------------+---------------------+--------------------+-----------------+----------------+--------------------------+-------------------+----------------------------+------------------------+-----------------+---------------+--------------+---------------------+-----------------+------------------+----------------+-----------------+---------------+-----------+---------------------+-------------+-----------------------+---------------------+-------------------+\n",
      "|        Record Date|Creditor Agency Name|Agency ID|Agency Site Type Code|Agency Site ID|    Agency Site Name|Source Agency Alpha|Source Agency Numeric|Source Agency Site ID|         Agency Name|Payment Agency ID|Agency Type Code|Payment Source Description|Payment Source Code|Payment Category Description|Payment Type Description|Payment Type Code|Payment Type ID|Debt Type Code|Debt Type Description|Taxable Indicator|Total Gross Amount|Total Net Amount|Total Gross Count|Total Net Count|Fiscal Year|Fiscal Quarter Number|Calendar Year|Calendar Quarter Number|Calendar Month Number|Calendar Day Number|\n",
      "+-------------------+--------------------+---------+---------------------+--------------+--------------------+-------------------+---------------------+---------------------+--------------------+-----------------+----------------+--------------------------+-------------------+----------------------------+------------------------+-----------------+---------------+--------------+---------------------+-----------------+------------------+----------------+-----------------+---------------+-----------+---------------------+-------------+-----------------------+---------------------+-------------------+\n",
      "|2022-10-01 00:00:00|Bureau of the Fis...|       83|              Federal|          33MK|33-MK-BUREAU OF F...|                 33|                   51|                   MK|Internal Revenue ...|              132|         Federal|                Tax Refund|                TAX|                         TDO|          Tax Refund EFT|               IE|             12|            FN|      FEDERAL NON-TAX|                N|             986.0|           986.0|                1|              1|       2023|                    1|         2022|                      4|                   10|                  1|\n",
      "|2022-10-01 00:00:00|Bureau of the Fis...|       83|              Federal|          33M7|33-M7-FISCAL SERV...|                 33|                   1C|                   M7|Department of Hom...|               21|           State|            Vendor payment|                VEN|                         TDO|              Vendor EFT|               VE|             13|            FN|      FEDERAL NON-TAX|                N|             289.6|           289.6|                5|              5|       2023|                    1|         2022|                      4|                   10|                  1|\n",
      "|2022-10-01 00:00:00|Bureau of the Fis...|       83|              Federal|          33M7|33-M7-FISCAL SERV...|                 33|                   18|                   M7|Office of Personn...|               17|         Federal|      Office of Personn...|                OPM|                         TDO|                 OPM EFT|               OE|              8|            FN|      FEDERAL NON-TAX|                N|          91000.38|        90170.87|             1351|           1340|       2023|                    1|         2022|                      4|                   10|                  1|\n",
      "|2022-10-01 00:00:00|Bureau of the Fis...|       83|              Federal|          33M7|33-M7-FISCAL SERV...|                 33|                   18|                   M7|Office of Personn...|               17|         Federal|      Office of Personn...|                OPM|                         TDO|               OPM Check|               OC|              8|            FN|      FEDERAL NON-TAX|                N|             992.8|          882.83|               13|             11|       2023|                    1|         2022|                      4|                   10|                  1|\n",
      "|2022-10-01 00:00:00|Bureau of the Fis...|       83|              Federal|          33M7|33-M7-FISCAL SERV...|                 33|                   03|                   M7|Dept. of Health &...|                3|         Federal|            Vendor payment|                VEN|                         TDO|              Vendor EFT|               VE|             13|            FN|      FEDERAL NON-TAX|                N|           1352.94|         1352.94|               19|             19|       2023|                    1|         2022|                      4|                   10|                  1|\n",
      "+-------------------+--------------------+---------+---------------------+--------------+--------------------+-------------------+---------------------+---------------------+--------------------+-----------------+----------------+--------------------------+-------------------+----------------------------+------------------------+-----------------+---------------+--------------+---------------------+-----------------+------------------+----------------+-----------------+---------------+-----------+---------------------+-------------+-----------------------+---------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read a Parquet file from local instance directory\n",
    "file_input = 'data/TOP_FedClct_20221001_20221001.parquet'\n",
    "\n",
    "df = spark.read.parquet(file_input) \n",
    "df.printSchema()\n",
    "df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75cfbaba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: data/TOP_FedClct_20221001_20221001.csv to s3://wc2h-dtl-prd-datawork/rmyers07/data/TOP_FedClct_20221001_20221001.csv\n",
      "2023-04-19 17:00:47     920049 TOP_FedClct_20221001_20221001.csv\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# copy local CSV file to S3 using AWS CLI\n",
    "aws s3 cp data/TOP_FedClct_20221001_20221001.csv s3://wc2h-dtl-prd-datawork/rmyers07/data/TOP_FedClct_20221001_20221001.csv\n",
    "    \n",
    "aws s3 ls s3://wc2h-dtl-prd-datawork/rmyers07/data/TOP_FedClct_20221001_20221001.csv    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b3ff27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record Date,Creditor Agency Name,Agency ID,Agency Site Type Code,Agency Site ID,Agency Site Name,Source Agency Alpha,Source Agency Numeric,Source Agency Site ID,Agency Name,Payment Agency ID,Agency Type Code,Payment Source Description,Payment Source Code,Payment Category Description,Payment Type Description,Payment Type Code,Payment Type ID,Debt Type Code,Debt Type Description,Taxable Indicator,Total Gross Amount,Total Net Amount,Total Gross Count,Total Net Count,Fiscal Year,Fiscal Quarter Number,Calendar Year,Calendar Quarter Number,Calendar Month Number,Calendar Day Number\n",
      "2022-10-01,Bureau of the Fiscal Service,83,Federal,33MK,33-MK-BUREAU OF FISCAL SERVICE,33,51,MK,Internal Revenue Service,132,Federal,Tax Refund,TAX,TDO,Tax Refund EFT,IE,12,FN,FEDERAL NON-TAX,N,986.00,986.00,1,1,2023,1,2022,4,10,01\n",
      "2022-10-01,Bureau of the Fiscal Service,83,Federal,33M7,33-M7-FISCAL SERVICE - DMSC,33,1C,M7,Department of Homeland Security,21,State,Vendor payment,VEN,TDO,Vendor EFT,VE,13,FN,FEDERAL NON-TAX,N,289.60,289.60,5,5,2023,1,2022,4,10,01\n",
      "2022-10-01,Bureau of the Fiscal Service,83,Federal,33M7,33-M7-FISCAL SERVICE - DMSC,33,18,M7,Office of Personnel Management,17,Federal,Office of Personnel Management,OPM,TDO,OPM EFT,OE,8,FN,FEDERAL NON-TAX,N,91000.38,90170.87,1351,1340,2023,1,2022,4,10,01\n",
      "2022-10-01,Bureau of the Fiscal Service,83,Federal,33M7,33-M7-FISCAL SERVICE - DMSC,33,18,M7,Office of Personnel Management,17,Federal,Office of Personnel Management,OPM,TDO,OPM Check,OC,8,FN,FEDERAL NON-TAX,N,992.80,882.83,13,11,2023,1,2022,4,10,01\n",
      "2022-10-01,Bureau of the Fiscal Service,83,Federal,33M7,33-M7-FISCAL SERVICE - DMSC,33,03,M7,Dept. of Health & Human Services,3,Federal,Vendor payment,VEN,TDO,Vendor EFT,VE,13,FN,FEDERAL NON-TAX,N,1352.94,1352.94,19,19,2023,1,2022,4,10,01\n",
      "2022-10-01,Bureau of the Fiscal Service,83,Federal,33M2,33-M2-DMSOC - EAST,33,27,M2,Social Security Administration,51,Federal,Social Security Administration,SSA,TDO,SSA EFT,SE,11,FN,FEDERAL NON-TAX,N,197.42,197.42,2,2,2023,1,2022,4,10,01\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file from S3 using Python AWS SDK\n",
    "import boto3\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "s3_bucket = 'wc2h-dtl-prd-datawork'\n",
    "s3_key = 'rmyers07/data/TOP_FedClct_20221001_20221001.csv'\n",
    "\n",
    "s3_obj = s3.get_object(Bucket=s3_bucket, Key=s3_key )\n",
    "data = s3_obj['Body'].read().decode('utf-8')\n",
    "\n",
    "for n,line in enumerate(data.split('\\n')):\n",
    "    print(line)\n",
    "    if n > 5:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5adb97bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['AWS_DEFAULT_REGION'] = 'us-gov-west-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "393ccb62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/19 17:01:05 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "+-------------------+--------------------+---------+---------------------+--------------+--------------------+-------------------+---------------------+---------------------+--------------------+-----------------+----------------+--------------------------+-------------------+----------------------------+------------------------+-----------------+---------------+--------------+---------------------+-----------------+------------------+----------------+-----------------+---------------+-----------+---------------------+-------------+-----------------------+---------------------+-------------------+\n",
      "|        Record Date|Creditor Agency Name|Agency ID|Agency Site Type Code|Agency Site ID|    Agency Site Name|Source Agency Alpha|Source Agency Numeric|Source Agency Site ID|         Agency Name|Payment Agency ID|Agency Type Code|Payment Source Description|Payment Source Code|Payment Category Description|Payment Type Description|Payment Type Code|Payment Type ID|Debt Type Code|Debt Type Description|Taxable Indicator|Total Gross Amount|Total Net Amount|Total Gross Count|Total Net Count|Fiscal Year|Fiscal Quarter Number|Calendar Year|Calendar Quarter Number|Calendar Month Number|Calendar Day Number|\n",
      "+-------------------+--------------------+---------+---------------------+--------------+--------------------+-------------------+---------------------+---------------------+--------------------+-----------------+----------------+--------------------------+-------------------+----------------------------+------------------------+-----------------+---------------+--------------+---------------------+-----------------+------------------+----------------+-----------------+---------------+-----------+---------------------+-------------+-----------------------+---------------------+-------------------+\n",
      "|2022-10-01 00:00:00|Bureau of the Fis...|       83|              Federal|          33MK|33-MK-BUREAU OF F...|                 33|                   51|                   MK|Internal Revenue ...|              132|         Federal|                Tax Refund|                TAX|                         TDO|          Tax Refund EFT|               IE|             12|            FN|      FEDERAL NON-TAX|                N|             986.0|           986.0|                1|              1|       2023|                    1|         2022|                      4|                   10|                  1|\n",
      "|2022-10-01 00:00:00|Bureau of the Fis...|       83|              Federal|          33M7|33-M7-FISCAL SERV...|                 33|                   1C|                   M7|Department of Hom...|               21|           State|            Vendor payment|                VEN|                         TDO|              Vendor EFT|               VE|             13|            FN|      FEDERAL NON-TAX|                N|             289.6|           289.6|                5|              5|       2023|                    1|         2022|                      4|                   10|                  1|\n",
      "|2022-10-01 00:00:00|Bureau of the Fis...|       83|              Federal|          33M7|33-M7-FISCAL SERV...|                 33|                   18|                   M7|Office of Personn...|               17|         Federal|      Office of Personn...|                OPM|                         TDO|                 OPM EFT|               OE|              8|            FN|      FEDERAL NON-TAX|                N|          91000.38|        90170.87|             1351|           1340|       2023|                    1|         2022|                      4|                   10|                  1|\n",
      "|2022-10-01 00:00:00|Bureau of the Fis...|       83|              Federal|          33M7|33-M7-FISCAL SERV...|                 33|                   18|                   M7|Office of Personn...|               17|         Federal|      Office of Personn...|                OPM|                         TDO|               OPM Check|               OC|              8|            FN|      FEDERAL NON-TAX|                N|             992.8|          882.83|               13|             11|       2023|                    1|         2022|                      4|                   10|                  1|\n",
      "|2022-10-01 00:00:00|Bureau of the Fis...|       83|              Federal|          33M7|33-M7-FISCAL SERV...|                 33|                   03|                   M7|Dept. of Health &...|                3|         Federal|            Vendor payment|                VEN|                         TDO|              Vendor EFT|               VE|             13|            FN|      FEDERAL NON-TAX|                N|           1352.94|         1352.94|               19|             19|       2023|                    1|         2022|                      4|                   10|                  1|\n",
      "+-------------------+--------------------+---------+---------------------+--------------+--------------------+-------------------+---------------------+---------------------+--------------------+-----------------+----------------+--------------------------+-------------------+----------------------------+------------------------+-----------------+---------------+--------------+---------------------+-----------------+------------------+----------------+-----------------+---------------+-----------+---------------------+-------------+-----------------------+---------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file from S3 into a Spark data frame\n",
    "s3_url_input = 's3a://wc2h-dtl-prd-datawork/rmyers07/data/TOP_FedClct_20221001_20221001.csv'\n",
    "\n",
    "df = spark.read \\\n",
    "    .format(\"com.databricks.spark.csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .option(\"delimiter\", \",\") \\\n",
    "    .load(s3_url_input) \n",
    "\n",
    "df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47d613bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "An error occurred (AccessDenied) when calling the ListObjectsV2 operation: Access Denied\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'# Use AWS CLI to list objects in publicly-accessible S3 parquet data set (AWS US East Region)\\naws s3 ls s3://amazon-reviews-pds/parquet/product_category=Electronics/\\n\\n# WC2H fails , DAAB LAB works \\n'' returned non-zero exit status 255.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbash\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m# Use AWS CLI to list objects in publicly-accessible S3 parquet data set (AWS US East Region)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43maws s3 ls s3://amazon-reviews-pds/parquet/product_category=Electronics/\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# WC2H fails , DAAB LAB works \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2422\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2420\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2421\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2422\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/IPython/core/magics/script.py:153\u001b[0m, in \u001b[0;36mScriptMagics._make_script_magic.<locals>.named_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     line \u001b[38;5;241m=\u001b[39m script\n\u001b[0;32m--> 153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshebang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/IPython/core/magics/script.py:305\u001b[0m, in \u001b[0;36mScriptMagics.shebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mraise_error \u001b[38;5;129;01mand\u001b[39;00m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;66;03m# If we get here and p.returncode is still None, we must have\u001b[39;00m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;66;03m# killed it but not yet seen its return code. We don't wait for it,\u001b[39;00m\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;66;03m# in case it's stuck in uninterruptible sleep. -9 = SIGKILL\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     rc \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m9\u001b[39m\n\u001b[0;32m--> 305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(rc, cell)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'# Use AWS CLI to list objects in publicly-accessible S3 parquet data set (AWS US East Region)\\naws s3 ls s3://amazon-reviews-pds/parquet/product_category=Electronics/\\n\\n# WC2H fails , DAAB LAB works \\n'' returned non-zero exit status 255."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Use AWS CLI to list objects in publicly-accessible S3 parquet data set (AWS US East Region)\n",
    "aws s3 ls s3://amazon-reviews-pds/parquet/product_category=Electronics/\n",
    "\n",
    "# WC2H fails , DAAB LAB works "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c95ebfe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/19 17:01:30 WARN FileStreamSink: Assume no metadata directory. Error while looking for metadata directory in the path: s3a://amazon-reviews-pds/parquet/product_category=Electronics/.\n",
      "java.nio.file.AccessDeniedException: s3a://amazon-reviews-pds/parquet/product_category=Electronics: getFileStatus on s3a://amazon-reviews-pds/parquet/product_category=Electronics: com.amazonaws.services.s3.model.AmazonS3Exception: Access Denied (Service: Amazon S3; Status Code: 403; Error Code: AccessDenied; Request ID: F5MHM91CXG1DS44V; S3 Extended Request ID: pf2wVkrV4DaS5LSkASbptKf1NRkxsA+v6fUK/WlE8MMhOG8cRqhJT4TApp4wG0MSWbRVaBQ1ToQ=; Proxy: null), S3 Extended Request ID: pf2wVkrV4DaS5LSkASbptKf1NRkxsA+v6fUK/WlE8MMhOG8cRqhJT4TApp4wG0MSWbRVaBQ1ToQ=:AccessDenied\n",
      "\tat org.apache.hadoop.fs.s3a.S3AUtils.translateException(S3AUtils.java:249)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AUtils.translateException(S3AUtils.java:170)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.s3GetFileStatus(S3AFileSystem.java:3348)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.innerGetFileStatus(S3AFileSystem.java:3185)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.isDirectory(S3AFileSystem.java:4277)\n",
      "\tat org.apache.spark.sql.execution.streaming.FileStreamSink$.hasMetadata(FileStreamSink.scala:54)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:370)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:228)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:210)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:210)\n",
      "\tat org.apache.spark.sql.DataFrameReader.parquet(DataFrameReader.scala:562)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: com.amazonaws.services.s3.model.AmazonS3Exception: Access Denied (Service: Amazon S3; Status Code: 403; Error Code: AccessDenied; Request ID: F5MHM91CXG1DS44V; S3 Extended Request ID: pf2wVkrV4DaS5LSkASbptKf1NRkxsA+v6fUK/WlE8MMhOG8cRqhJT4TApp4wG0MSWbRVaBQ1ToQ=; Proxy: null), S3 Extended Request ID: pf2wVkrV4DaS5LSkASbptKf1NRkxsA+v6fUK/WlE8MMhOG8cRqhJT4TApp4wG0MSWbRVaBQ1ToQ=\n",
      "\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.handleErrorResponse(AmazonHttpClient.java:1828)\n",
      "\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.handleServiceErrorResponse(AmazonHttpClient.java:1412)\n",
      "\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeOneRequest(AmazonHttpClient.java:1374)\n",
      "\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeHelper(AmazonHttpClient.java:1145)\n",
      "\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.doExecute(AmazonHttpClient.java:802)\n",
      "\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeWithTimer(AmazonHttpClient.java:770)\n",
      "\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.execute(AmazonHttpClient.java:744)\n",
      "\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.access$500(AmazonHttpClient.java:704)\n",
      "\tat com.amazonaws.http.AmazonHttpClient$RequestExecutionBuilderImpl.execute(AmazonHttpClient.java:686)\n",
      "\tat com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:550)\n",
      "\tat com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:530)\n",
      "\tat com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:5227)\n",
      "\tat com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:5173)\n",
      "\tat com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:5167)\n",
      "\tat com.amazonaws.services.s3.AmazonS3Client.listObjectsV2(AmazonS3Client.java:963)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.lambda$listObjects$7(S3AFileSystem.java:2116)\n",
      "\tat org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.lambda$trackDurationOfOperation$5(IOStatisticsBinding.java:499)\n",
      "\tat org.apache.hadoop.fs.s3a.Invoker.retryUntranslated(Invoker.java:412)\n",
      "\tat org.apache.hadoop.fs.s3a.Invoker.retryUntranslated(Invoker.java:375)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.listObjects(S3AFileSystem.java:2107)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.s3GetFileStatus(S3AFileSystem.java:3322)\n",
      "\t... 21 more\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o55.parquet.\n: java.nio.file.AccessDeniedException: s3a://amazon-reviews-pds/parquet/product_category=Electronics: getFileStatus on s3a://amazon-reviews-pds/parquet/product_category=Electronics: com.amazonaws.services.s3.model.AmazonS3Exception: Forbidden (Service: Amazon S3; Status Code: 403; Error Code: 403 Forbidden; Request ID: F5MQ6TG9P4R2K8ZY; S3 Extended Request ID: qIMZnXkvE5eHd36Sdi+UwheiT9Rv5g2cG9qGDb9X1KqDvWw+w4S161Lmd/lBX2iMe8Y7pGKCnR0=; Proxy: null), S3 Extended Request ID: qIMZnXkvE5eHd36Sdi+UwheiT9Rv5g2cG9qGDb9X1KqDvWw+w4S161Lmd/lBX2iMe8Y7pGKCnR0=:403 Forbidden\n\tat org.apache.hadoop.fs.s3a.S3AUtils.translateException(S3AUtils.java:249)\n\tat org.apache.hadoop.fs.s3a.S3AUtils.translateException(S3AUtils.java:170)\n\tat org.apache.hadoop.fs.s3a.S3AFileSystem.s3GetFileStatus(S3AFileSystem.java:3286)\n\tat org.apache.hadoop.fs.s3a.S3AFileSystem.innerGetFileStatus(S3AFileSystem.java:3185)\n\tat org.apache.hadoop.fs.s3a.S3AFileSystem.getFileStatus(S3AFileSystem.java:3053)\n\tat org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1760)\n\tat org.apache.hadoop.fs.s3a.S3AFileSystem.exists(S3AFileSystem.java:4263)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$checkAndGlobPathIfNecessary$4(DataSource.scala:784)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$checkAndGlobPathIfNecessary$4$adapted(DataSource.scala:782)\n\tat org.apache.spark.util.ThreadUtils$.$anonfun$parmap$2(ThreadUtils.scala:372)\n\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n\tat scala.util.Success.map(Try.scala:213)\n\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n\tat java.base/java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1426)\n\tat java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)\n\tat java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)\n\tat java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)\n\tat java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)\n\tat java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:177)\nCaused by: com.amazonaws.services.s3.model.AmazonS3Exception: Forbidden (Service: Amazon S3; Status Code: 403; Error Code: 403 Forbidden; Request ID: F5MQ6TG9P4R2K8ZY; S3 Extended Request ID: qIMZnXkvE5eHd36Sdi+UwheiT9Rv5g2cG9qGDb9X1KqDvWw+w4S161Lmd/lBX2iMe8Y7pGKCnR0=; Proxy: null), S3 Extended Request ID: qIMZnXkvE5eHd36Sdi+UwheiT9Rv5g2cG9qGDb9X1KqDvWw+w4S161Lmd/lBX2iMe8Y7pGKCnR0=\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.handleErrorResponse(AmazonHttpClient.java:1828)\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.handleServiceErrorResponse(AmazonHttpClient.java:1412)\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeOneRequest(AmazonHttpClient.java:1374)\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeHelper(AmazonHttpClient.java:1145)\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.doExecute(AmazonHttpClient.java:802)\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeWithTimer(AmazonHttpClient.java:770)\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.execute(AmazonHttpClient.java:744)\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.access$500(AmazonHttpClient.java:704)\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutionBuilderImpl.execute(AmazonHttpClient.java:686)\n\tat com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:550)\n\tat com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:530)\n\tat com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:5227)\n\tat com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:5173)\n\tat com.amazonaws.services.s3.AmazonS3Client.getObjectMetadata(AmazonS3Client.java:1360)\n\tat org.apache.hadoop.fs.s3a.S3AFileSystem.lambda$getObjectMetadata$6(S3AFileSystem.java:2066)\n\tat org.apache.hadoop.fs.s3a.Invoker.retryUntranslated(Invoker.java:412)\n\tat org.apache.hadoop.fs.s3a.Invoker.retryUntranslated(Invoker.java:375)\n\tat org.apache.hadoop.fs.s3a.S3AFileSystem.getObjectMetadata(S3AFileSystem.java:2056)\n\tat org.apache.hadoop.fs.s3a.S3AFileSystem.getObjectMetadata(S3AFileSystem.java:2032)\n\tat org.apache.hadoop.fs.s3a.S3AFileSystem.s3GetFileStatus(S3AFileSystem.java:3273)\n\t... 20 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Read a publicly-accessible S3 parquet data set into a Spark dataframe (AWS US East Region)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43ms3a://amazon-reviews-pds/parquet/product_category=Electronics/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m df\u001b[38;5;241m.\u001b[39mprintSchema()\n\u001b[1;32m      4\u001b[0m df\u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;241m5\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/pyspark/sql/readwriter.py:364\u001b[0m, in \u001b[0;36mDataFrameReader.parquet\u001b[0;34m(self, *paths, **options)\u001b[0m\n\u001b[1;32m    353\u001b[0m int96RebaseMode \u001b[38;5;241m=\u001b[39m options\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint96RebaseMode\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_opts(\n\u001b[1;32m    355\u001b[0m     mergeSchema\u001b[38;5;241m=\u001b[39mmergeSchema,\n\u001b[1;32m    356\u001b[0m     pathGlobFilter\u001b[38;5;241m=\u001b[39mpathGlobFilter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m     int96RebaseMode\u001b[38;5;241m=\u001b[39mint96RebaseMode,\n\u001b[1;32m    362\u001b[0m )\n\u001b[0;32m--> 364\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_seq\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_spark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/pyspark/sql/utils.py:190\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    192\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o55.parquet.\n: java.nio.file.AccessDeniedException: s3a://amazon-reviews-pds/parquet/product_category=Electronics: getFileStatus on s3a://amazon-reviews-pds/parquet/product_category=Electronics: com.amazonaws.services.s3.model.AmazonS3Exception: Forbidden (Service: Amazon S3; Status Code: 403; Error Code: 403 Forbidden; Request ID: F5MQ6TG9P4R2K8ZY; S3 Extended Request ID: qIMZnXkvE5eHd36Sdi+UwheiT9Rv5g2cG9qGDb9X1KqDvWw+w4S161Lmd/lBX2iMe8Y7pGKCnR0=; Proxy: null), S3 Extended Request ID: qIMZnXkvE5eHd36Sdi+UwheiT9Rv5g2cG9qGDb9X1KqDvWw+w4S161Lmd/lBX2iMe8Y7pGKCnR0=:403 Forbidden\n\tat org.apache.hadoop.fs.s3a.S3AUtils.translateException(S3AUtils.java:249)\n\tat org.apache.hadoop.fs.s3a.S3AUtils.translateException(S3AUtils.java:170)\n\tat org.apache.hadoop.fs.s3a.S3AFileSystem.s3GetFileStatus(S3AFileSystem.java:3286)\n\tat org.apache.hadoop.fs.s3a.S3AFileSystem.innerGetFileStatus(S3AFileSystem.java:3185)\n\tat org.apache.hadoop.fs.s3a.S3AFileSystem.getFileStatus(S3AFileSystem.java:3053)\n\tat org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1760)\n\tat org.apache.hadoop.fs.s3a.S3AFileSystem.exists(S3AFileSystem.java:4263)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$checkAndGlobPathIfNecessary$4(DataSource.scala:784)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$checkAndGlobPathIfNecessary$4$adapted(DataSource.scala:782)\n\tat org.apache.spark.util.ThreadUtils$.$anonfun$parmap$2(ThreadUtils.scala:372)\n\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n\tat scala.util.Success.map(Try.scala:213)\n\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n\tat java.base/java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1426)\n\tat java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)\n\tat java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)\n\tat java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)\n\tat java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)\n\tat java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:177)\nCaused by: com.amazonaws.services.s3.model.AmazonS3Exception: Forbidden (Service: Amazon S3; Status Code: 403; Error Code: 403 Forbidden; Request ID: F5MQ6TG9P4R2K8ZY; S3 Extended Request ID: qIMZnXkvE5eHd36Sdi+UwheiT9Rv5g2cG9qGDb9X1KqDvWw+w4S161Lmd/lBX2iMe8Y7pGKCnR0=; Proxy: null), S3 Extended Request ID: qIMZnXkvE5eHd36Sdi+UwheiT9Rv5g2cG9qGDb9X1KqDvWw+w4S161Lmd/lBX2iMe8Y7pGKCnR0=\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.handleErrorResponse(AmazonHttpClient.java:1828)\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.handleServiceErrorResponse(AmazonHttpClient.java:1412)\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeOneRequest(AmazonHttpClient.java:1374)\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeHelper(AmazonHttpClient.java:1145)\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.doExecute(AmazonHttpClient.java:802)\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeWithTimer(AmazonHttpClient.java:770)\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.execute(AmazonHttpClient.java:744)\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.access$500(AmazonHttpClient.java:704)\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutionBuilderImpl.execute(AmazonHttpClient.java:686)\n\tat com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:550)\n\tat com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:530)\n\tat com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:5227)\n\tat com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:5173)\n\tat com.amazonaws.services.s3.AmazonS3Client.getObjectMetadata(AmazonS3Client.java:1360)\n\tat org.apache.hadoop.fs.s3a.S3AFileSystem.lambda$getObjectMetadata$6(S3AFileSystem.java:2066)\n\tat org.apache.hadoop.fs.s3a.Invoker.retryUntranslated(Invoker.java:412)\n\tat org.apache.hadoop.fs.s3a.Invoker.retryUntranslated(Invoker.java:375)\n\tat org.apache.hadoop.fs.s3a.S3AFileSystem.getObjectMetadata(S3AFileSystem.java:2056)\n\tat org.apache.hadoop.fs.s3a.S3AFileSystem.getObjectMetadata(S3AFileSystem.java:2032)\n\tat org.apache.hadoop.fs.s3a.S3AFileSystem.s3GetFileStatus(S3AFileSystem.java:3273)\n\t... 20 more\n"
     ]
    }
   ],
   "source": [
    "# Read a publicly-accessible S3 parquet data set into a Spark dataframe (AWS US East Region)\n",
    "df = spark.read.parquet(\"s3a://amazon-reviews-pds/parquet/product_category=Electronics/\")\n",
    "df.printSchema()\n",
    "df.show(5)\n",
    "\n",
    "# WC2H fails , DAAB LAB works "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efeea372",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
